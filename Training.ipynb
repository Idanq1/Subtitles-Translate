{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae61ca9-ea43-4706-b893-1e13f6b7afe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T10:29:15.098219600Z",
     "start_time": "2024-01-09T10:29:15.073286700Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c9b0c0-accf-4f52-9be0-d918d60f7710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T10:09:05.444559Z",
     "start_time": "2024-01-09T10:09:05.431593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "hebrew_folder_path = r\"Data\\Hebrew\"\n",
    "english_folder_path = r\"Data\\English\"\n",
    "dataset_path = r\"Data\\Modified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f204d8a4-73c5-4f84-ba43-b19a266e90b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T21:48:24.697010500Z",
     "start_time": "2024-01-09T21:48:24.633728500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Hebrew  \\\n0                                 , ג'ול ורנס כתב פעם   \n1                          ,שים שתי ספינות בים הפתוח\"   \n2               ,ללא רוח או שפל\", .\"מתישהו, הן ייפגשו   \n3     .ככה הוריי הכירו, .כמו שתי ספינות שנועדו להיפגש   \n4                                   .זה בסדר, זה בסדר   \n...                                               ...   \n5383                                              ומה   \n5384                                             סיזר   \n5385                                              עשה   \n5386                                          .עבורנו   \n5387                                            .סיזר   \n\n                                                English  Safe     Hebrew_st  \\\n0                               Jules Verne once wrote,  True  00:01:05,990   \n1                        \"Put two ships in the open sea  True  00:01:07,920   \n2      without wind or tide,, they will come together.\"  True  00:01:10,420   \n3     That's how my parents met., Like two ships des...  True  00:01:35,850   \n4                                            It's okay.  True  00:01:54,400   \n...                                                 ...   ...           ...   \n5383                                        And what...  True  02:10:34,342   \n5384                                          Caesar...  True  02:10:38,176   \n5385                                             did...  True  02:10:42,743   \n5386                                            for us.  True  02:10:45,609   \n5387                                          Caesar...  True  02:11:52,712   \n\n          Hebrew_e    English_st     English_e  \n0     00:01:07,920  00:01:06,109  00:01:07,444  \n1     00:01:10,420  00:01:08,027  00:01:10,989  \n2     00:01:13,760  00:01:11,156  00:01:13,575  \n3     00:01:40,520  00:01:36,181  00:01:40,268  \n4     00:01:55,600  00:01:54,282  00:01:55,283  \n...            ...           ...           ...  \n5383  02:10:35,809  02:10:34,661  02:10:36,046  \n5384  02:10:39,509  02:10:38,415  02:10:39,917  \n5385  02:10:43,676  02:10:43,086  02:10:44,179  \n5386  02:10:47,176  02:10:45,839  02:10:47,341  \n5387  02:11:53,912  02:11:53,115  02:11:54,284  \n\n[5388 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hebrew</th>\n      <th>English</th>\n      <th>Safe</th>\n      <th>Hebrew_st</th>\n      <th>Hebrew_e</th>\n      <th>English_st</th>\n      <th>English_e</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>, ג'ול ורנס כתב פעם</td>\n      <td>Jules Verne once wrote,</td>\n      <td>True</td>\n      <td>00:01:05,990</td>\n      <td>00:01:07,920</td>\n      <td>00:01:06,109</td>\n      <td>00:01:07,444</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,שים שתי ספינות בים הפתוח\"</td>\n      <td>\"Put two ships in the open sea</td>\n      <td>True</td>\n      <td>00:01:07,920</td>\n      <td>00:01:10,420</td>\n      <td>00:01:08,027</td>\n      <td>00:01:10,989</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>,ללא רוח או שפל\", .\"מתישהו, הן ייפגשו</td>\n      <td>without wind or tide,, they will come together.\"</td>\n      <td>True</td>\n      <td>00:01:10,420</td>\n      <td>00:01:13,760</td>\n      <td>00:01:11,156</td>\n      <td>00:01:13,575</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>.ככה הוריי הכירו, .כמו שתי ספינות שנועדו להיפגש</td>\n      <td>That's how my parents met., Like two ships des...</td>\n      <td>True</td>\n      <td>00:01:35,850</td>\n      <td>00:01:40,520</td>\n      <td>00:01:36,181</td>\n      <td>00:01:40,268</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>.זה בסדר, זה בסדר</td>\n      <td>It's okay.</td>\n      <td>True</td>\n      <td>00:01:54,400</td>\n      <td>00:01:55,600</td>\n      <td>00:01:54,282</td>\n      <td>00:01:55,283</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5383</th>\n      <td>ומה</td>\n      <td>And what...</td>\n      <td>True</td>\n      <td>02:10:34,342</td>\n      <td>02:10:35,809</td>\n      <td>02:10:34,661</td>\n      <td>02:10:36,046</td>\n    </tr>\n    <tr>\n      <th>5384</th>\n      <td>סיזר</td>\n      <td>Caesar...</td>\n      <td>True</td>\n      <td>02:10:38,176</td>\n      <td>02:10:39,509</td>\n      <td>02:10:38,415</td>\n      <td>02:10:39,917</td>\n    </tr>\n    <tr>\n      <th>5385</th>\n      <td>עשה</td>\n      <td>did...</td>\n      <td>True</td>\n      <td>02:10:42,743</td>\n      <td>02:10:43,676</td>\n      <td>02:10:43,086</td>\n      <td>02:10:44,179</td>\n    </tr>\n    <tr>\n      <th>5386</th>\n      <td>.עבורנו</td>\n      <td>for us.</td>\n      <td>True</td>\n      <td>02:10:45,609</td>\n      <td>02:10:47,176</td>\n      <td>02:10:45,839</td>\n      <td>02:10:47,341</td>\n    </tr>\n    <tr>\n      <th>5387</th>\n      <td>.סיזר</td>\n      <td>Caesar...</td>\n      <td>True</td>\n      <td>02:11:52,712</td>\n      <td>02:11:53,912</td>\n      <td>02:11:53,115</td>\n      <td>02:11:54,284</td>\n    </tr>\n  </tbody>\n</table>\n<p>5388 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_csvs(path):\n",
    "    df = pd.DataFrame({})\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        tmp = pd.read_csv(file_path)\n",
    "        df = pd.concat([df, tmp], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df = combine_csvs(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46e1dd9-c3d7-49f3-854b-a88c0e0c7ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T10:13:02.044499Z",
     "start_time": "2024-01-09T10:13:02.020541900Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(lang)\n",
    "    tensor = tokenizer.texts_to_sequences(lang)\n",
    "    tensor = pad_sequences(tensor, padding='post')\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(df['Hebrew'])\n",
    "target_tensor, targ_lang_tokenizer = tokenize(df['English'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T10:13:22.565454100Z",
     "start_time": "2024-01-09T10:13:22.474698100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T10:14:57.834663300Z",
     "start_time": "2024-01-09T10:14:57.735937600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "# Build the Encoder-Decoder model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_inp_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units)),\n",
    "    tf.keras.layers.RepeatVector(target_tensor_train.shape[1]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True)),\n",
    "    tf.keras.layers.Dense(vocab_tar_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:39:20.676127600Z",
     "start_time": "2024-01-09T15:39:12.079769100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/220\n",
      "30/30 [==============================] - 68s 2s/step - loss: 3.5660 - val_loss: 2.7314\n",
      "Epoch 2/220\n",
      "30/30 [==============================] - 59s 2s/step - loss: 2.6465 - val_loss: 2.6727\n",
      "Epoch 3/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.4593 - val_loss: 2.6223\n",
      "Epoch 4/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.3533 - val_loss: 2.6457\n",
      "Epoch 5/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.2739 - val_loss: 2.6529\n",
      "Epoch 6/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.2132 - val_loss: 2.6908\n",
      "Epoch 7/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.1621 - val_loss: 2.7385\n",
      "Epoch 8/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.1046 - val_loss: 2.7768\n",
      "Epoch 9/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.0494 - val_loss: 2.8393\n",
      "Epoch 10/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 2.0148 - val_loss: 2.8746\n",
      "Epoch 11/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.9561 - val_loss: 2.9210\n",
      "Epoch 12/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.8958 - val_loss: 2.9706\n",
      "Epoch 13/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.8317 - val_loss: 3.0817\n",
      "Epoch 14/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.7764 - val_loss: 3.1141\n",
      "Epoch 15/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.7214 - val_loss: 3.1275\n",
      "Epoch 16/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.6547 - val_loss: 3.2015\n",
      "Epoch 17/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.5888 - val_loss: 3.2502\n",
      "Epoch 18/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.5529 - val_loss: 3.2885\n",
      "Epoch 19/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.5262 - val_loss: 3.3201\n",
      "Epoch 20/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.4599 - val_loss: 3.3652\n",
      "Epoch 21/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.3668 - val_loss: 3.4128\n",
      "Epoch 22/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.2956 - val_loss: 3.4543\n",
      "Epoch 23/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.2271 - val_loss: 3.5471\n",
      "Epoch 24/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.1719 - val_loss: 3.5713\n",
      "Epoch 25/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.1056 - val_loss: 3.6397\n",
      "Epoch 26/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.0364 - val_loss: 3.7008\n",
      "Epoch 27/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.9750 - val_loss: 3.7417\n",
      "Epoch 28/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.9074 - val_loss: 3.7829\n",
      "Epoch 29/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.8494 - val_loss: 3.8586\n",
      "Epoch 30/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.7735 - val_loss: 3.9277\n",
      "Epoch 31/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.7105 - val_loss: 3.9607\n",
      "Epoch 32/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.6513 - val_loss: 3.9633\n",
      "Epoch 33/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.5896 - val_loss: 4.0302\n",
      "Epoch 34/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.5325 - val_loss: 4.1102\n",
      "Epoch 35/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.4734 - val_loss: 4.1120\n",
      "Epoch 36/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.4149 - val_loss: 4.1979\n",
      "Epoch 37/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.3679 - val_loss: 4.2389\n",
      "Epoch 38/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.3108 - val_loss: 4.3039\n",
      "Epoch 39/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.2610 - val_loss: 4.3321\n",
      "Epoch 40/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.2140 - val_loss: 4.4209\n",
      "Epoch 41/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.1737 - val_loss: 4.4778\n",
      "Epoch 42/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.1417 - val_loss: 4.5221\n",
      "Epoch 43/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.1172 - val_loss: 4.5426\n",
      "Epoch 44/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0999 - val_loss: 4.6019\n",
      "Epoch 45/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0859 - val_loss: 4.6196\n",
      "Epoch 46/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0743 - val_loss: 4.6751\n",
      "Epoch 47/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0648 - val_loss: 4.6819\n",
      "Epoch 48/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0577 - val_loss: 4.7285\n",
      "Epoch 49/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0507 - val_loss: 4.7518\n",
      "Epoch 50/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0417 - val_loss: 4.7881\n",
      "Epoch 51/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0354 - val_loss: 4.8048\n",
      "Epoch 52/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0300 - val_loss: 4.8304\n",
      "Epoch 53/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0287 - val_loss: 4.8331\n",
      "Epoch 54/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0260 - val_loss: 4.8775\n",
      "Epoch 55/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0237 - val_loss: 4.8895\n",
      "Epoch 56/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0219 - val_loss: 4.9028\n",
      "Epoch 57/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0206 - val_loss: 4.9103\n",
      "Epoch 58/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0195 - val_loss: 4.9444\n",
      "Epoch 59/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0191 - val_loss: 4.9559\n",
      "Epoch 60/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0174 - val_loss: 4.9734\n",
      "Epoch 61/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0157 - val_loss: 4.9844\n",
      "Epoch 62/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0161 - val_loss: 5.0027\n",
      "Epoch 63/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0160 - val_loss: 5.0095\n",
      "Epoch 64/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0163 - val_loss: 5.0203\n",
      "Epoch 65/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0165 - val_loss: 5.0308\n",
      "Epoch 66/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0164 - val_loss: 5.0484\n",
      "Epoch 67/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0240 - val_loss: 5.0324\n",
      "Epoch 68/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0759 - val_loss: 4.9198\n",
      "Epoch 69/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.1798 - val_loss: 4.7003\n",
      "Epoch 70/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.3281 - val_loss: 4.6113\n",
      "Epoch 71/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.4045 - val_loss: 4.4800\n",
      "Epoch 72/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.2981 - val_loss: 4.5650\n",
      "Epoch 73/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.1581 - val_loss: 4.6689\n",
      "Epoch 74/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0867 - val_loss: 4.7436\n",
      "Epoch 75/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0441 - val_loss: 4.8199\n",
      "Epoch 76/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0253 - val_loss: 4.8540\n",
      "Epoch 77/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0164 - val_loss: 4.8881\n",
      "Epoch 78/220\n",
      "30/30 [==============================] - 59s 2s/step - loss: 0.0133 - val_loss: 4.9053\n",
      "Epoch 79/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0118 - val_loss: 4.9323\n",
      "Epoch 80/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0102 - val_loss: 4.9465\n",
      "Epoch 81/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0097 - val_loss: 4.9601\n",
      "Epoch 82/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0094 - val_loss: 4.9835\n",
      "Epoch 83/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0091 - val_loss: 4.9875\n",
      "Epoch 84/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0086 - val_loss: 4.9958\n",
      "Epoch 85/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0083 - val_loss: 5.0060\n",
      "Epoch 86/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0080 - val_loss: 5.0163\n",
      "Epoch 87/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0082 - val_loss: 5.0276\n",
      "Epoch 88/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0075 - val_loss: 5.0417\n",
      "Epoch 89/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0074 - val_loss: 5.0520\n",
      "Epoch 90/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0078 - val_loss: 5.0616\n",
      "Epoch 91/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0073 - val_loss: 5.0685\n",
      "Epoch 92/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0077 - val_loss: 5.0689\n",
      "Epoch 93/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0071 - val_loss: 5.0819\n",
      "Epoch 94/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0073 - val_loss: 5.0858\n",
      "Epoch 95/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0065 - val_loss: 5.0938\n",
      "Epoch 96/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0068 - val_loss: 5.1041\n",
      "Epoch 97/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0067 - val_loss: 5.1070\n",
      "Epoch 98/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0065 - val_loss: 5.1189\n",
      "Epoch 99/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0069 - val_loss: 5.1208\n",
      "Epoch 100/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0066 - val_loss: 5.1315\n",
      "Epoch 101/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0063 - val_loss: 5.1350\n",
      "Epoch 102/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0061 - val_loss: 5.1413\n",
      "Epoch 103/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0062 - val_loss: 5.1455\n",
      "Epoch 104/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0066 - val_loss: 5.1595\n",
      "Epoch 105/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0058 - val_loss: 5.1651\n",
      "Epoch 106/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0060 - val_loss: 5.1634\n",
      "Epoch 107/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0064 - val_loss: 5.1710\n",
      "Epoch 108/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0061 - val_loss: 5.1834\n",
      "Epoch 109/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0063 - val_loss: 5.1861\n",
      "Epoch 110/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 5.1857\n",
      "Epoch 111/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0058 - val_loss: 5.1987\n",
      "Epoch 112/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0063 - val_loss: 5.1978\n",
      "Epoch 113/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0063 - val_loss: 5.2021\n",
      "Epoch 114/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0060 - val_loss: 5.2084\n",
      "Epoch 115/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0059 - val_loss: 5.2151\n",
      "Epoch 116/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0060 - val_loss: 5.2147\n",
      "Epoch 117/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0058 - val_loss: 5.2240\n",
      "Epoch 118/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0058 - val_loss: 5.2324\n",
      "Epoch 119/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0061 - val_loss: 5.2255\n",
      "Epoch 120/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0059 - val_loss: 5.2384\n",
      "Epoch 121/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0059 - val_loss: 5.2415\n",
      "Epoch 122/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0057 - val_loss: 5.2487\n",
      "Epoch 123/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0058 - val_loss: 5.2508\n",
      "Epoch 124/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0058 - val_loss: 5.2619\n",
      "Epoch 125/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0059 - val_loss: 5.2634\n",
      "Epoch 126/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0061 - val_loss: 5.2622\n",
      "Epoch 127/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0053 - val_loss: 5.2686\n",
      "Epoch 128/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0058 - val_loss: 5.2586\n",
      "Epoch 129/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0064 - val_loss: 5.2884\n",
      "Epoch 130/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0058 - val_loss: 5.2687\n",
      "Epoch 131/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0060 - val_loss: 5.2928\n",
      "Epoch 132/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 5.2903\n",
      "Epoch 133/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0056 - val_loss: 5.2933\n",
      "Epoch 134/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0059 - val_loss: 5.2822\n",
      "Epoch 135/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 5.3030\n",
      "Epoch 136/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0055 - val_loss: 5.2923\n",
      "Epoch 137/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0059 - val_loss: 5.3157\n",
      "Epoch 138/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0060 - val_loss: 5.3014\n",
      "Epoch 139/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0054 - val_loss: 5.3086\n",
      "Epoch 140/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0061 - val_loss: 5.3114\n",
      "Epoch 141/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0054 - val_loss: 5.3251\n",
      "Epoch 142/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 5.3298\n",
      "Epoch 143/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0057 - val_loss: 5.3244\n",
      "Epoch 144/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0054 - val_loss: 5.3476\n",
      "Epoch 145/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0054 - val_loss: 5.3338\n",
      "Epoch 146/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0053 - val_loss: 5.3496\n",
      "Epoch 147/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0052 - val_loss: 5.3458\n",
      "Epoch 148/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0051 - val_loss: 5.3551\n",
      "Epoch 149/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0057 - val_loss: 5.3599\n",
      "Epoch 150/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0049 - val_loss: 5.3603\n",
      "Epoch 151/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0053 - val_loss: 5.3665\n",
      "Epoch 152/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0053 - val_loss: 5.3758\n",
      "Epoch 153/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0055 - val_loss: 5.3718\n",
      "Epoch 154/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0051 - val_loss: 5.3834\n",
      "Epoch 155/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0054 - val_loss: 5.3851\n",
      "Epoch 156/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0049 - val_loss: 5.3899\n",
      "Epoch 157/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0047 - val_loss: 5.3984\n",
      "Epoch 158/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0055 - val_loss: 5.3871\n",
      "Epoch 159/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0047 - val_loss: 5.3985\n",
      "Epoch 160/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0054 - val_loss: 5.4056\n",
      "Epoch 161/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0049 - val_loss: 5.3988\n",
      "Epoch 162/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0048 - val_loss: 5.4067\n",
      "Epoch 163/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0055 - val_loss: 5.4159\n",
      "Epoch 164/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0047 - val_loss: 5.4246\n",
      "Epoch 165/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0054 - val_loss: 5.4300\n",
      "Epoch 166/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0052 - val_loss: 5.4317\n",
      "Epoch 167/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0051 - val_loss: 5.4365\n",
      "Epoch 168/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0058 - val_loss: 5.4381\n",
      "Epoch 169/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0065 - val_loss: 5.4139\n",
      "Epoch 170/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0622 - val_loss: 5.1566\n",
      "Epoch 171/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.6731 - val_loss: 4.3019\n",
      "Epoch 172/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.0066 - val_loss: 3.9132\n",
      "Epoch 173/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.5717 - val_loss: 4.0799\n",
      "Epoch 174/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.2365 - val_loss: 4.2529\n",
      "Epoch 175/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0966 - val_loss: 4.3558\n",
      "Epoch 176/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0426 - val_loss: 4.4697\n",
      "Epoch 177/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0234 - val_loss: 4.5157\n",
      "Epoch 178/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0152 - val_loss: 4.5622\n",
      "Epoch 179/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0103 - val_loss: 4.5992\n",
      "Epoch 180/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0090 - val_loss: 4.6301\n",
      "Epoch 181/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0080 - val_loss: 4.6374\n",
      "Epoch 182/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0074 - val_loss: 4.6577\n",
      "Epoch 183/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0069 - val_loss: 4.6742\n",
      "Epoch 184/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0068 - val_loss: 4.6900\n",
      "Epoch 185/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0067 - val_loss: 4.7067\n",
      "Epoch 186/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0064 - val_loss: 4.7182\n",
      "Epoch 187/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0066 - val_loss: 4.7233\n",
      "Epoch 188/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0063 - val_loss: 4.7396\n",
      "Epoch 189/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0059 - val_loss: 4.7489\n",
      "Epoch 190/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0061 - val_loss: 4.7657\n",
      "Epoch 191/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 4.7692\n",
      "Epoch 192/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0058 - val_loss: 4.7876\n",
      "Epoch 193/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0060 - val_loss: 4.7923\n",
      "Epoch 194/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0062 - val_loss: 4.7979\n",
      "Epoch 195/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0057 - val_loss: 4.8123\n",
      "Epoch 196/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0056 - val_loss: 4.8143\n",
      "Epoch 197/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 4.8293\n",
      "Epoch 198/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 4.8307\n",
      "Epoch 199/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0053 - val_loss: 4.8450\n",
      "Epoch 200/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0055 - val_loss: 4.8548\n",
      "Epoch 201/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0053 - val_loss: 4.8546\n",
      "Epoch 202/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0055 - val_loss: 4.8645\n",
      "Epoch 203/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0055 - val_loss: 4.8727\n",
      "Epoch 204/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 4.8713\n",
      "Epoch 205/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0056 - val_loss: 4.8840\n",
      "Epoch 206/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0050 - val_loss: 4.8922\n",
      "Epoch 207/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0052 - val_loss: 4.8909\n",
      "Epoch 208/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0052 - val_loss: 4.9160\n",
      "Epoch 209/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0057 - val_loss: 4.9039\n",
      "Epoch 210/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0052 - val_loss: 4.9106\n",
      "Epoch 211/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0051 - val_loss: 4.9159\n",
      "Epoch 212/220\n",
      "30/30 [==============================] - 57s 2s/step - loss: 0.0051 - val_loss: 4.9330\n",
      "Epoch 213/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0052 - val_loss: 4.9240\n",
      "Epoch 214/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0044 - val_loss: 4.9399\n",
      "Epoch 215/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0048 - val_loss: 4.9462\n",
      "Epoch 216/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0048 - val_loss: 4.9498\n",
      "Epoch 217/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0048 - val_loss: 4.9518\n",
      "Epoch 218/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0050 - val_loss: 4.9599\n",
      "Epoch 219/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0050 - val_loss: 4.9641\n",
      "Epoch 220/220\n",
      "30/30 [==============================] - 58s 2s/step - loss: 0.0044 - val_loss: 4.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x23953a3f730>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tf.data dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=220, validation_data=(input_tensor_val, target_tensor_val), steps_per_epoch=steps_per_epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T19:10:55.957070100Z",
     "start_time": "2024-01-09T15:39:20.683097500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "don't knows. see?\n"
     ]
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    sentence = inp_lang_tokenizer.texts_to_sequences([sentence])\n",
    "    sentence = pad_sequences(sentence, maxlen=input_tensor.shape[1], padding='post')\n",
    "    predictions = model.predict(sentence)\n",
    "\n",
    "    # Select the index of the maximum value in each prediction\n",
    "    predicted_sequence = [np.argmax(pred) for pred in predictions[0]]\n",
    "\n",
    "    # Convert the sequence of indices to text\n",
    "    translated_sentence = targ_lang_tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
    "    return translated_sentence\n",
    "\n",
    "# Example translation\n",
    "print(translate(\"די כבר\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T21:56:23.861882800Z",
     "start_time": "2024-01-09T21:56:23.673387300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
